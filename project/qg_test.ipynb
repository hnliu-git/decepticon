{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "universal-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gersa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "# neptune\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification\n",
    "from time import sleep\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.nn import functional as F\n",
    "from models.t5 import *\n",
    "from data.data import *\n",
    "from data.prerpocessing import *\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bronze-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_path =  \"D:\\Github/decepticon/Processed_New\"\n",
    "        self.batch_size =  16\n",
    "        self.num_workers =  0\n",
    "        self.pretrained_model = \"t5-small\"\n",
    "        self.pretrained_eval_model = \"iarfmoose/bert-base-cased-qa-evaluator\"\n",
    "        self.tokenizer_len = 32102 ## manual\n",
    "        self.padding_id = 0\n",
    "        self.special_tokens = [\"<answer>\", \"<context>\"]\n",
    "    def to_dict(self):\n",
    "        out = dict()\n",
    "        out[\"data_path\"] = self.data_path\n",
    "        out[\"batch_size\"] = self.batch_size\n",
    "        out[\"num_workers\"] = self.num_workers\n",
    "        out[\"pretrained_model\"] = self.pretrained_model\n",
    "        out[\"tokenizer_len\"] = self.tokenizer_len\n",
    "        out[\"padding_id\"] = self.padding_id\n",
    "        out[\"special_tokens\"] = self.special_tokens\n",
    "        return out\n",
    "\n",
    "hparams=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "detailed-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d45ce16fcb747158adf00165a9786a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2af32a42924157bec2b1789652cfcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b96d8d41f4589b6955ff374dd45e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b2cd85f6504fcd8b00bfab9e16cdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5FinetuneForRACE.load_from_checkpoint(\"D:/Github/decepticon/project/checkpoints/0_02.ckpt\").to(device)\n",
    "evaluator = BertForSequenceClassification.from_pretrained(hparams.pretrained_eval_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alien-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataModule: Custom collate function is detected\n",
      "SETUP: Training Dataset\n",
      "SETUP: Validation Dataset\n",
      "SETUP: Test Dataset\n"
     ]
    }
   ],
   "source": [
    "data_module = RaceDataModule(hparams, custom_collate_fn = RaceDataModule.t5_collate_fn)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dental-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5FinetuneForRACE.datamodule = data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cheap-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data_module.val_dataloader()))\n",
    "output = model.generate_questions(x[\"input_ids\"].to(device), decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "systematic-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What would be the best title for the passage?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = output[9][0]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "polar-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.datamodule.tokenizer.decode(x[\"input_ids\"][2]).replace(\"<answer>\", \"\").lstrip().split(\"<context>\")[0]\n",
    "answer = \"9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "curious-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tokenizer(text = output[9][0], text_pair =  answer,  \n",
    "              padding = True,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "disabled-importance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.1364, -1.8405]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(i[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-colony",
   "metadata": {},
   "source": [
    "# ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expected-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(content):\n",
    "    model.eval()        \n",
    "    generated = model.model.generate(input_ids = x[\"input_ids\"].to(device), \n",
    "                                     num_beams = 6,\n",
    "                                     num_return_sequences = 5,\n",
    "                                     max_length = 50,\n",
    "                                     no_repeat_ngram_size = 2,\n",
    "                                     early_stopping = True)\n",
    "\n",
    "    output = []\n",
    "    for sequence in generated[:]:\n",
    "        output.append(data_module.tokenizer.decode(sequence, skip_special_tokens= True, clean_up_tokenization_spaces = True))\n",
    "    content = data_module.tokenizer.decode(content[\"input_ids\"][0], skip_special_tokens= False, clean_up_tokenization_spaces = True)\n",
    "    return output, content, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wrapped-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "GROUND TRUTH: The Sherman Antitrust Act _.\n",
      "GENERATED 0: The Sherman Antitrust Act _.\n",
      "GENERATED 1: According to the passage, the early tycoons _.\n",
      "GENERATED 2: It can be inferred from the passage that the Sherman Antitrust Act _.\n",
      "GENERATED 3: The first tycoons built successful businesses because they _.\n",
      "GENERATED 4: The Sherman Antitrust Act was passed because it _.\n",
      "GENERATED 5: According to the passage, tycoons _.\n",
      "GENERATED 6: The early tycoons _.\n",
      "ANSWER: sought to eliminate monopolies in favor of competition in the market-place\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Why are ECAs important now?\n",
      "GENERATED 0: What does the passage mainly talk about?\n",
      "GENERATED 1: Which of the following is TRUE about ECAs?\n",
      "GENERATED 2: What does the passage mainly tell us about ECAs?\n",
      "GENERATED 3: Which of the following is NOT true about ECAs?\n",
      "GENERATED 4: What's the main idea of the passage?\n",
      "GENERATED 5: Why did the author walk down the hall?\n",
      "GENERATED 6: What did the author think of his grandma?\n",
      "ANSWER: They prepare the students for their future.\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Which of the following should be avoided when taking selfies?\n",
      "GENERATED 0: What's the main problem with selfies?\n",
      "GENERATED 1: What's the main problem with taking selfies?\n",
      "GENERATED 2: Which of the following can make the photo appealing?\n",
      "GENERATED 3: According to the passage, which of the following can make the photo appealing?\n",
      "GENERATED 4: Which of the following can make a selfie appealing?\n",
      "GENERATED 5: The maternity package is designed to give all expectant mothers _.\n",
      "GENERATED 6: The maternity package is designed to give all children in Finland _.\n",
      "ANSWER: A busy background.\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: What can be the subject of this passage?\n",
      "GENERATED 0: Which of the following is TRUE according to the passage?\n",
      "GENERATED 1: Which of the following statements is TRUE according to the passage?\n",
      "GENERATED 2: Which of the following is NOT true according to the passage?\n",
      "GENERATED 3: Which of the following is true according to the passage?\n",
      "GENERATED 4: According to the passage, which of the following is TRUE?\n",
      "GENERATED 5: Which of the following is TRUE according to the passage?\n",
      "GENERATED 6: Which of the following statements is TRUE according to the passage?\n",
      "ANSWER: People across the world get married in different ways and for different reasons.\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Why didn't the fish eat our night crawlers?\n",
      "GENERATED 0: Which of the following is TRUE according to the passage?\n",
      "GENERATED 1: Which of the following is NOT true according to the passage?\n",
      "GENERATED 2: Which of the following is true according to the passage?\n",
      "GENERATED 3: Which of the following is TRUE according to the text?\n",
      "GENERATED 4: Which of the following statements is TRUE?\n",
      "GENERATED 5: From the passage we can learn that the writer's father was _.\n",
      "GENERATED 6: According to the passage, the author's father was _.\n",
      "ANSWER: The reason was not clear.\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Why did the author feel nervous when collecting the afternoon mails? _\n",
      "GENERATED 0: Why did the author ask her husband to set up a time to talk about her finances?\n",
      "GENERATED 1: Why did the author ask her husband to set up a time each week?\n",
      "GENERATED 2: How did the author feel when she saw the mails?\n",
      "GENERATED 3: What did the author think of her husband?\n",
      "GENERATED 4: Which of the following is true about the author?\n",
      "GENERATED 5: What did the author think of the Financial Dates?\n",
      "GENERATED 6: What did the author think of the financial dates?\n",
      "ANSWER: She could feel the pressure of the huge debt.\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Which of the following majors can get a job easily?\n",
      "GENERATED 0: According to Allmen-Vinniage, students have majored in _.\n",
      "GENERATED 1: According to Allmen-Vinniage, students who do find jobs started preparing two years ago have majored in _.\n",
      "GENERATED 2: According to Allmen-Vinniage, students who find jobs started preparing two years ago have majored in _.\n",
      "GENERATED 3: According to Allmen-Vinniage, students have majored in one of the few fields that are still hot.\n",
      "GENERATED 4: According to Allmen-Vinniage, students have majored in one of the few fields that are still hot.\n",
      "GENERATED 5: Ryan Stewart would like to _.\n",
      "GENERATED 6: Ryan Stewart may _.\n",
      "ANSWER: accounting\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: The old saying referred to in the passage tells us that _.\n",
      "GENERATED 0: It can be inferred from the passage that _.\n",
      "GENERATED 1: We can infer from the passage that _.\n",
      "GENERATED 2: We can learn from the passage that _.\n",
      "GENERATED 3: The writer thinks that _.\n",
      "GENERATED 4: According to the passage, we can infer that _.\n",
      "GENERATED 5: It can be inferred from the passage that _.\n",
      "GENERATED 6: We can infer from the passage that _.\n",
      "ANSWER: eating apples regularly does lots of good to our health\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: We can learn from the text that _.\n",
      "GENERATED 0: We can learn from the passage that _.\n",
      "GENERATED 1: We can infer from the passage that _.\n",
      "GENERATED 2: It can be inferred from the passage that_.\n",
      "GENERATED 3: According to the passage,we know that _.\n",
      "GENERATED 4: From the passage we know that _.\n",
      "GENERATED 5: What is the passage mainly about?\n",
      "GENERATED 6: What is the main idea of the passage?\n",
      "ANSWER: different people can bear different amounts of stress\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: The passage is most probably entitled \" _ \".\n",
      "GENERATED 0: What is the best title for the passage?\n",
      "GENERATED 1: What would be the best title for the passage?\n",
      "GENERATED 2: What's the best title for the passage?\n",
      "GENERATED 3: What's the best title of the passage?\n",
      "GENERATED 4: What is the best title for this passage?\n",
      "GENERATED 5: In American superstitions, the number three is _.\n",
      "GENERATED 6: It can be inferred from the passage that American superstitions are_.\n",
      "ANSWER: American Superstitions\n",
      "-----------------------------------------\n",
      "GROUND TRUTH: Which of the following is the hest title for the passage?\n",
      "GENERATED 0: What would be the best title for the passage?\n",
      "GENERATED 1: Which of the following is the best title for the passage?\n",
      "GENERATED 2: What's the best title for the passage?\n",
      "GENERATED 3: What is the best title for the passage?\n",
      "GENERATED 4: The best title for the passage is _.\n",
      "GENERATED 5: The author realized his biggest weakness, Public Speaking, because _.\n",
      "GENERATED 6: The author realized his biggest weakness in Public Speaking because _.\n",
      "ANSWER: Practice Makes a Man a Better Speechmaker\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for x, y in data_module.val_dataloader():\n",
    "    output = generate_question(x)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"GROUND TRUTH: %s\" %data_module.tokenizer.decode(y[\"input_ids\"][0], skip_special_tokens= True, clean_up_tokenization_spaces = True))\n",
    "    for i, q in enumerate(output[0]):\n",
    "        print(\"GENERATED %s: %s\"  %(i, \"\".join(q)))\n",
    "    print(\"ANSWER: %s\" % \"\".join(output[1]).split(\"<context>\")[0].replace(\"<answer>\", \"\").lstrip())\n",
    "    j += 1\n",
    "    if j > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fixed-separation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  363,  133,  ...,    0,    0,    0],\n",
       "        [   0, 4073,   13,  ...,    0,    0,    0],\n",
       "        [   0,  363,   31,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   0, 4073,   13,  ...,    1,    0,    0],\n",
       "        [   0, 4073,   13,  ...,    1,    0,    0],\n",
       "        [   0, 4073,   13,  ...,   58,    1,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bearing-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 444])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"input_ids\"].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "boxed-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 17])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "better-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.model.generate(input_ids = x[\"input_ids\"].to(device), \n",
    "                                     num_beams = 6,\n",
    "                                     num_return_sequences = 5,\n",
    "                                     max_length = 30,\n",
    "                                     no_repeat_ngram_size = 2,\n",
    "                                     early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "younger-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generated.view(16, 5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sustainable-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]\n",
    "for indx in range(16):    \n",
    "    for sequence in g[indx]:\n",
    "        output.append(data_module.tokenizer.decode(sequence, skip_special_tokens= True, clean_up_tokenization_spaces = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "domestic-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 444])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "willing-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = data_module.tokenizer.batch_decode(generated, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "n=5\n",
    "inal = [my_list[i * n:(i + 1) * n] for i in range((len(my_list) + n - 1) // n )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesser-square",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-aeea9597be84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inal' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer(inal[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-tournament",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

import pytorch_lightning as pl

# Pytorch Import:
import torch
import random
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from torch.optim.lr_scheduler import ReduceLROnPlateau


class RaceRNNModule(pl.LightningModule):

    @staticmethod
    def translate(vocab, ans, output, tgt):
        """
        Args:
            vocab dictionary of [index, word]
            ans (seq_len) np.array
            tgt (seq_len) np.array
            output (seq_len, vocab_size) np.array
        """
        output = np.argmax(output, axis=1)
        ans_str = ' '.join([vocab[i] for i in ans if i != 0])
        tgt_str = ' '.join([vocab[i] for i in tgt if i != 0])
        out_str = ' '.join([vocab[i] for i in output if i != 0])
        print("\n============================")
        print("ANS:", ans_str)
        print("TGT:", tgt_str)
        print("OUT:", out_str)

    def __init__(self, hparams):
        super(RaceRNNModule, self).__init__()
        self.hparams = hparams
        # Encoder:
        num_directions = 2 if self.hparams.bidirectional else 1
        self.embedding = nn.Embedding(self.hparams.vocab_size + 1, hparams.embed_dim)
        self.en_gru = nn.GRU(
            self.hparams.embed_dim,
            self.hparams.hidden_size,
            self.hparams.num_layers,
            dropout=self.hparams.dropout if self.hparams.num_layers else 0,
            bidirectional=self.hparams.bidirectional,
            batch_first=True
        )
        self.en_fc = nn.Linear(
            self.hparams.num_layers*num_directions,
            self.hparams.num_layers
        )

        # Decoder:
        self.de_gru = nn.GRU(
            self.hparams.embed_dim,
            self.hparams.hidden_size,
            self.hparams.num_layers,
            dropout=self.hparams.dropout if self.hparams.num_layers else 0,
            batch_first=True
        )
        self.de_fc = nn.Linear(
            self.hparams.hidden_size,
            self.hparams.vocab_size
        )

    def encode(self, input, hidden=None):
        """ Args:
                input (batch, seq_len): Input sequence.
                hidden (num_layers*num_directions, batch, hidden_size): Initial states.

            Returns:
                output (batch, seq_len, num_directions*hidden_size): Outputs at every step.
                hidden (num_layers, batch, hidden_size): Final state.
        """
        x = self.embedding(input)
        outputs, hidden = self.en_gru(x, hidden)
        hidden = hidden.permute(1, 2, 0)
        hidden = self.en_fc(hidden)
        hidden = hidden.permute(2, 0, 1)
        return outputs, hidden.contiguous()

    def forward(self, hidden, pred_len=32, target=None, teacher_forcing=False):
        """ Args:
                hidden (num_layers, batch, hidden_size): States of the GRU.
                pred_len (int): Length of predicted sequence.
                target (batch, seq_len, embed_dim): Target sequence. If None,
                    the output sequence is generated by feeding the output
                    of the previous timestep (teacher_forcing has to be False).
                teacher_forcing (bool): Boolean to apply teacher forcing.

            Returns:
                outputs (batch, seq_len, vocab_size): Tensor of log-probabilities
                    of words in the target language.
                hidden of shape (1, batch_size, hidden_size): New states of the GRU.
        """
        if target is None:
            assert not teacher_forcing, 'Cannot use teacher forcing without a target sequence.'
        else:
            pred_len = target.shape[1]

        # Determine constants:
        batch = hidden.shape[1]
        # Initial value to feed to the GRU:
        x = torch.zeros((batch, 1), device=hidden.device).long()
        # Sequence to record the predicted values:
        outputs = list()
        for i in range(pred_len):
            # Embed the value at ith time step:
            x = self.embedding(x)
            output, hidden = self.de_gru(x, hidden)
            output = F.log_softmax(self.de_fc(output),dim=2)
            outputs.append(output)
            # If teacher_forcing then use the target value at current step
            # Else use the predicted value at previous step:
            if teacher_forcing:
                x = target[:, i:i+1]
            else:
                x = torch.argmax(output, dim=2)
        # Concatenate predicted values:
        outputs = torch.cat(outputs, dim=1)
        return outputs, hidden

    def configure_optimizers(self):
        optimizer = Adam(self.parameters(), lr=self.hparams.learning_rate)
        scheduler = ReduceLROnPlateau(optimizer, mode="min", factor=1e-1, patience=2, verbose=True)
        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}

    def training_step(self, batch, batch_idx):
        art, que, ans = batch['articles']['input_ids'], batch['questions']['input_ids'], batch['answers']['input_ids']
        x, y = torch.cat([ans, art], dim=1).long(), que.long()
        _, h = self.encode(x)
        y_hat, _ = self(h, None, y, True)
        y_hat = y_hat.reshape(-1, y_hat.shape[-1])
        y = y.reshape(-1)
        loss = F.nll_loss(y_hat, y)
        return {"loss": loss}

    def training_epoch_end(self, outputs):
        loss = torch.stack([x["loss"] for x in outputs]).mean()
        self.log("loss", loss, logger=True)

    def validation_step(self, batch, batch_idx):
        art, que, ans = batch['articles']['input_ids'], batch['questions']['input_ids'], batch['answers']['input_ids']
        x, y = torch.cat([ans, art], dim=1).long(), que.long()
        _, h = self.encode(x)
        y_hat, _ = self(h, None, y, False)
        y_h_rs = y_hat.reshape(-1, y_hat.shape[-1])
        y_rs = y.reshape(-1)
        val_loss = F.nll_loss(y_h_rs, y_rs)
        return {'val_loss': val_loss, "ans": torch.squeeze(ans[0, :]).cpu().numpy(),
                "que_h": torch.squeeze(y_hat[0, :, :]).cpu().numpy(), "que": torch.squeeze(y[0, :]).cpu().numpy()}

    def validation_epoch_end(self, outputs):
        val_loss = torch.stack([x["val_loss"] for x in outputs]).mean()
        item = random.choice(outputs)
        self.translate(self.hparams.idx2w, item['ans'], item['que_h'], item['que'])
        self.log("val_loss", val_loss, prog_bar=True, logger=True)